{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literal Listener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Christopher Leung\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2020\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [colors_overview.ipynb](colors_overview.ipynb) for set-up in instructions and other background details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colors import ColorsCorpusReader\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_color_selector import (\n",
    "    ColorizedNeuralListener, create_example_dataset)\n",
    "import utils\n",
    "from utils import START_SYMBOL, END_SYMBOL, UNK_SYMBOL\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.fix_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS_SRC_FILENAME = os.path.join(\n",
    "    \"data\", \"colors\", \"filteredCorpus.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All two-word examples as a dev corpus\n",
    "\n",
    "So that you don't have to sit through excessively long training runs during development, I suggest working with the two-word-only subset of the corpus until you enter into the late stages of system testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_corpus = ColorsCorpusReader(\n",
    "    COLORS_SRC_FILENAME, \n",
    "    word_count=None, \n",
    "    normalize_colors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_examples = list(dev_corpus.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This subset has about one-third the examples of the full corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46994"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev dataset\n",
    "\n",
    "The first step is to extract the raw color and raw texts from the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_rawcols, dev_texts = zip(*[[ex.colors, ex.contents] for ex in dev_examples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw color representations are suitable inputs to a model, but the texts are just strings, so they can't really be processed as-is. Question 1 asks you to do some tokenizing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random train–test split for development\n",
    "\n",
    "For the sake of development runs, we create a random train–test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_rawcols_train, dev_rawcols_test, dev_texts_train, dev_texts_test = \\\n",
    "    train_test_split(dev_rawcols, dev_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colors_utils import heuristic_ending_tokenizer\n",
    "\n",
    "def tokenize_example(s):\n",
    "    \n",
    "    # Improve me!\n",
    "    \n",
    "    return [START_SYMBOL] + heuristic_ending_tokenizer(s) + [END_SYMBOL]\n",
    "\n",
    "def clean_test_and_training(dev_seqs_train, dev_seqs_test):    \n",
    "    vocab = {}\n",
    "    for toks in dev_seqs_train+dev_seqs_test:\n",
    "        for w in toks:\n",
    "            if w not in vocab:\n",
    "                vocab[w]=0\n",
    "            vocab[w]+=1\n",
    "    removal_candidates = {k:v for k, v in vocab.items() if v == 1 }\n",
    "    \n",
    "    dev_seqs_train = [[w if w not in removal_candidates else UNK_SYMBOL for w in toks] for toks in dev_seqs_train]\n",
    "\n",
    "    dev_seqs_test = [[w if w not in removal_candidates else UNK_SYMBOL for w in toks] for toks in dev_seqs_test]\n",
    "    return dev_seqs_train, dev_seqs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'aqua', '</s>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_example(dev_texts_train[376])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the tokenizer is working, run the following cell to tokenize your inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_seqs_train = [tokenize_example(s) for s in dev_texts_train]\n",
    "\n",
    "dev_seqs_test = [tokenize_example(s) for s in dev_texts_test]\n",
    "\n",
    "dev_seqs_train, dev_seqs_test = clean_test_and_training(dev_seqs_train, dev_seqs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use only the train set to derive a vocabulary for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_vocab = sorted({w for toks in dev_seqs_train for w in toks}) + [UNK_SYMBOL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important that the `UNK_SYMBOL` is included somewhere in this list. Test examples with word not seen in training will be mapped to `UNK_SYMBOL`. If you model's vocab is the same as your train vocab, then `UNK_SYMBOL` will never be encountered during training, so it will be a random vector at test time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1551"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the color representations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "\n",
    "def represent_color_context(colors):\n",
    "    \n",
    "    # Improve me!\n",
    "    \n",
    "    return [represent_color(color) for color in colors]\n",
    "\n",
    "\n",
    "def represent_color(color):\n",
    "    import numpy.fft as fft\n",
    "    # Improve me!\n",
    "    #return color\n",
    "    #return colorsys.rgb_to_hsv(*color)\n",
    "    return fft.fft(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.07833333+0.j        , 0.24833333+0.19052559j,\n",
       "        0.24833333-0.19052559j]),\n",
       " array([ 0.88 +0.j        , -0.215-0.23382686j, -0.215+0.23382686j]),\n",
       " array([1.145+0.j        , 0.29 -0.37239092j, 0.29 +0.37239092j])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "represent_color_context(dev_rawcols_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the color representer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell just runs your `represent_color_context` on the train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_cols_train = [represent_color_context(colors) for colors in dev_rawcols_train]\n",
    "\n",
    "dev_cols_test = [represent_color_context(colors) for colors in dev_rawcols_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our preprocessing steps are complete, and we can fit a first model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial model\n",
    "\n",
    "The first model is configured right now to be a small model run for just a few iterations. It should be enough to get traction, but it's unlikely to be a great model. You are free to modify this configuration if you wish; it is here just for demonstration and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "dev_mod = ColorizedNeuralListener(\n",
    "    dev_vocab, \n",
    "    embed_dim=10, \n",
    "    hidden_dim=10, \n",
    "    max_iter=5, \n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = dev_mod.fit(dev_cols_train, dev_seqs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the model's predicted sequences given color context inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_mod.predict(dev_cols_test[:1], dev_seqs_train[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in [colors_overview.ipynb](colors_overview.ipynb), our primary metric is `listener_accuracy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_mod.listener_accuracy(dev_cols_test, dev_seqs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_seqs_train[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = np.random.normal(\n",
    "            loc=0, scale=0.01, size=(len(dev_vocab), 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literal Listener"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_color_seqs, toy_word_seqs, toy_vocab = create_example_dataset(\n",
    "    group_size=50, vec_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_color_seqs_train, toy_color_seqs_test, toy_word_seqs_train, toy_word_seqs_test = \\\n",
    "    train_test_split(toy_color_seqs, toy_word_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "toy_mod = ColorizedNeuralListener(\n",
    "    toy_vocab, \n",
    "    embed_dim=100, \n",
    "    embedding=embedding,\n",
    "    hidden_dim=100, \n",
    "    max_iter=100, \n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColorizedNeuralListenerEncoder cpu\n",
      "ColorizedNeuralListenerEncoderDecoder cpu\n",
      "Train: Epoch 1; err = 1.0984532833099365; time = 1.9314358234405518\n",
      "Train: Epoch 2; err = 1.0898754596710205; time = 0.028006315231323242\n",
      "Train: Epoch 3; err = 1.0627622604370117; time = 0.027005910873413086\n",
      "Train: Epoch 4; err = 1.046028971672058; time = 0.027005910873413086\n",
      "Train: Epoch 5; err = 1.0055944919586182; time = 0.027006149291992188\n",
      "Train: Epoch 6; err = 0.9819746017456055; time = 0.02600574493408203\n",
      "Train: Epoch 7; err = 0.9419035315513611; time = 0.026005983352661133\n",
      "Train: Epoch 8; err = 0.9108478426933289; time = 0.027006864547729492\n",
      "Train: Epoch 9; err = 0.8837128281593323; time = 0.027006149291992188\n",
      "Train: Epoch 10; err = 0.8716385960578918; time = 0.024005413055419922\n",
      "Train: Epoch 11; err = 0.8834823966026306; time = 0.02600574493408203\n",
      "Train: Epoch 12; err = 0.8806705474853516; time = 0.02300429344177246\n",
      "Train: Epoch 13; err = 0.8400679230690002; time = 0.024005651473999023\n",
      "Train: Epoch 14; err = 0.9506786465644836; time = 0.026006460189819336\n",
      "0.01\n",
      "tensor([0.2850, 0.1071, 0.6079], grad_fn=<MeanBackward1>) 0.8921207189559937\n",
      "Train: Epoch 15; err = 0.8921207189559937; time = 0.029006481170654297\n",
      "Train: Epoch 16; err = 0.8441532254219055; time = 0.027005672454833984\n",
      "Train: Epoch 17; err = 0.8724886775016785; time = 0.025005340576171875\n",
      "Train: Epoch 18; err = 0.8752371072769165; time = 0.025005817413330078\n",
      "Train: Epoch 19; err = 0.8739624619483948; time = 0.024005413055419922\n",
      "Train: Epoch 20; err = 0.8934453725814819; time = 0.025005817413330078\n",
      "Train: Epoch 21; err = 0.8557760119438171; time = 0.025005578994750977\n",
      "Train: Epoch 22; err = 0.8329371809959412; time = 0.02300548553466797\n",
      "Train: Epoch 23; err = 0.7979125380516052; time = 0.02500605583190918\n",
      "Train: Epoch 24; err = 0.812558114528656; time = 0.023005247116088867\n",
      "Train: Epoch 25; err = 0.8471009135246277; time = 0.02200460433959961\n",
      "Train: Epoch 26; err = 0.8141971826553345; time = 0.023005008697509766\n",
      "Train: Epoch 27; err = 0.7717984318733215; time = 0.023005247116088867\n",
      "Train: Epoch 28; err = 0.7764562964439392; time = 0.023005008697509766\n",
      "Train: Epoch 29; err = 0.7905493974685669; time = 0.02200460433959961\n",
      "0.01\n",
      "tensor([0.0153, 0.2598, 0.7249], grad_fn=<MeanBackward1>) 0.7915015816688538\n",
      "Train: Epoch 30; err = 0.7915015816688538; time = 0.025005578994750977\n",
      "Train: Epoch 31; err = 0.7739545702934265; time = 0.02300572395324707\n",
      "Train: Epoch 32; err = 0.7478412985801697; time = 0.024006128311157227\n",
      "Train: Epoch 33; err = 0.7452478408813477; time = 0.02200484275817871\n",
      "Train: Epoch 34; err = 0.7600048184394836; time = 0.022005558013916016\n",
      "Train: Epoch 35; err = 0.7511733174324036; time = 0.025005102157592773\n",
      "Train: Epoch 36; err = 0.7235067486763; time = 0.024006128311157227\n",
      "Train: Epoch 37; err = 0.732522189617157; time = 0.02400517463684082\n",
      "Train: Epoch 38; err = 0.740878701210022; time = 0.025006771087646484\n",
      "Train: Epoch 39; err = 0.7149868011474609; time = 0.028006553649902344\n",
      "Train: Epoch 40; err = 0.7206360101699829; time = 0.029007434844970703\n",
      "Train: Epoch 41; err = 0.7282382249832153; time = 0.02400493621826172\n",
      "Train: Epoch 42; err = 0.7051802277565002; time = 0.02600574493408203\n",
      "Train: Epoch 43; err = 0.7100186944007874; time = 0.025005817413330078\n",
      "Train: Epoch 44; err = 0.7082880139350891; time = 0.026006698608398438\n",
      "0.01\n",
      "tensor([0.0940, 0.0829, 0.8231], grad_fn=<MeanBackward1>) 0.6902030110359192\n",
      "Train: Epoch 45; err = 0.6902030110359192; time = 0.030007123947143555\n",
      "Train: Epoch 46; err = 0.7021974325180054; time = 0.027006149291992188\n",
      "Train: Epoch 47; err = 0.682494580745697; time = 0.02500462532043457\n",
      "Train: Epoch 48; err = 0.6877769231796265; time = 0.030007123947143555\n",
      "Train: Epoch 49; err = 0.6713600754737854; time = 0.024004697799682617\n",
      "Train: Epoch 50; err = 0.6783246994018555; time = 0.026005983352661133\n",
      "Train: Epoch 51; err = 0.6551051735877991; time = 0.027006149291992188\n",
      "Train: Epoch 52; err = 0.6732908487319946; time = 0.027005910873413086\n",
      "Train: Epoch 53; err = 0.6455791592597961; time = 0.026005983352661133\n",
      "Train: Epoch 54; err = 0.6401695609092712; time = 0.026005983352661133\n",
      "Train: Epoch 55; err = 0.6584830284118652; time = 0.026005983352661133\n",
      "Train: Epoch 56; err = 0.6345142126083374; time = 0.022005558013916016\n",
      "Train: Epoch 57; err = 0.613086998462677; time = 0.022005081176757812\n",
      "Train: Epoch 58; err = 0.6301698088645935; time = 0.023006916046142578\n",
      "Train: Epoch 59; err = 0.6340670585632324; time = 0.022005796432495117\n",
      "0.01\n",
      "tensor([0.0188, 0.0521, 0.9291], grad_fn=<MeanBackward1>) 0.6013460755348206\n",
      "Train: Epoch 60; err = 0.6013460755348206; time = 0.027007341384887695\n",
      "Train: Epoch 61; err = 0.599557101726532; time = 0.02400660514831543\n",
      "Train: Epoch 62; err = 0.613639771938324; time = 0.022005558013916016\n",
      "Train: Epoch 63; err = 0.5926448702812195; time = 0.024006128311157227\n",
      "Train: Epoch 64; err = 0.5850055813789368; time = 0.024005889892578125\n",
      "Train: Epoch 65; err = 0.5954168438911438; time = 0.026005983352661133\n",
      "Train: Epoch 66; err = 0.5789393782615662; time = 0.023005962371826172\n",
      "Train: Epoch 67; err = 0.5803846716880798; time = 0.025006532669067383\n",
      "Train: Epoch 68; err = 0.5817866921424866; time = 0.02100515365600586\n",
      "Train: Epoch 69; err = 0.5699566602706909; time = 0.022005319595336914\n",
      "Train: Epoch 70; err = 0.5769528746604919; time = 0.02300572395324707\n",
      "Train: Epoch 71; err = 0.5685474276542664; time = 0.023006200790405273\n",
      "Train: Epoch 72; err = 0.5706594586372375; time = 0.026006221771240234\n",
      "Train: Epoch 73; err = 0.5682390332221985; time = 0.02500605583190918\n",
      "Train: Epoch 74; err = 0.5655863285064697; time = 0.02500629425048828\n",
      "0.01\n",
      "tensor([0.0188, 0.0038, 0.9774], grad_fn=<MeanBackward1>) 0.566433310508728\n",
      "Train: Epoch 75; err = 0.566433310508728; time = 0.03000664710998535\n",
      "Train: Epoch 76; err = 0.5625095367431641; time = 0.02700662612915039\n",
      "Train: Epoch 77; err = 0.564177930355072; time = 0.02500605583190918\n",
      "Train: Epoch 78; err = 0.5606617331504822; time = 0.022004127502441406\n",
      "Train: Epoch 79; err = 0.5621708035469055; time = 0.02200484275817871\n",
      "Train: Epoch 80; err = 0.5594039559364319; time = 0.026005029678344727\n",
      "Train: Epoch 81; err = 0.5605319738388062; time = 0.023005247116088867\n",
      "Train: Epoch 82; err = 0.5584574341773987; time = 0.02300548553466797\n",
      "Train: Epoch 83; err = 0.5591877102851868; time = 0.026005268096923828\n",
      "Train: Epoch 84; err = 0.5577306151390076; time = 0.023006200790405273\n",
      "Train: Epoch 85; err = 0.5580690503120422; time = 0.026005268096923828\n",
      "Train: Epoch 86; err = 0.557173490524292; time = 0.02300548553466797\n",
      "Train: Epoch 87; err = 0.5571392774581909; time = 0.026006221771240234\n",
      "Train: Epoch 88; err = 0.556743323802948; time = 0.02300548553466797\n",
      "Train: Epoch 89; err = 0.5563850998878479; time = 0.0290069580078125\n",
      "0.01\n",
      "tensor([0.0023, 0.0054, 0.9924], grad_fn=<MeanBackward1>) 0.5563729405403137\n",
      "Train: Epoch 90; err = 0.5563729405403137; time = 0.0290067195892334\n",
      "Train: Epoch 91; err = 0.5558070540428162; time = 0.02300548553466797\n",
      "Train: Epoch 92; err = 0.5560033917427063; time = 0.025005340576171875\n",
      "Train: Epoch 93; err = 0.5553891658782959; time = 0.027005910873413086\n",
      "Train: Epoch 94; err = 0.5556008815765381; time = 0.029006242752075195\n",
      "Train: Epoch 95; err = 0.5551047921180725; time = 0.027006864547729492\n",
      "Train: Epoch 96; err = 0.555185079574585; time = 0.02300572395324707\n",
      "Train: Epoch 97; err = 0.554909348487854; time = 0.022005796432495117\n",
      "Train: Epoch 98; err = 0.5548048615455627; time = 0.02300572395324707\n",
      "Train: Epoch 99; err = 0.5547425150871277; time = 0.02300548553466797\n",
      "Train: Epoch 100; err = 0.5545052289962769; time = 0.023005247116088867\n"
     ]
    }
   ],
   "source": [
    "_ = toy_mod.fit(toy_color_seqs_train, toy_word_seqs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 / 38 1.0\n"
     ]
    }
   ],
   "source": [
    "preds = toy_mod.predict(toy_color_seqs_test, toy_word_seqs_test)\n",
    "correct = sum([1 if x == 2 else 0 for x in preds])\n",
    "print(correct, \"/\", len(preds), correct/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that worked, then you can now try this model on SCC problems!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "dev_color_mod = ColorizedNeuralListener(\n",
    "    dev_vocab,\n",
    "    embed_dim=100,\n",
    "    embedding=embedding,\n",
    "    hidden_dim=100, \n",
    "    max_iter=100,\n",
    "    batch_size=64,\n",
    "    dropout_prob=0.,\n",
    "    eta=0.001,\n",
    "    lr_rate=0.96,\n",
    "    warm_start=True,\n",
    "    device='cuda')\n",
    "# Uncomment line if you want to continue training the previous model\n",
    "# literal_listener.load_model(\"literal_listener.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColorizedNeuralListenerEncoder cuda\n",
      "ColorizedNeuralListenerEncoderDecoder cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Github\\cs224u\\torch_color_selector.py:77: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  color_seqs = torch.FloatTensor(color_seqs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Epoch 1; err = 574.3356761336327; time = 15.220709323883057\n",
      "Train: Epoch 2; err = 530.3089804053307; time = 14.730923891067505\n",
      "Train: Epoch 3; err = 520.3168433904648; time = 14.783754587173462\n",
      "Train: Epoch 4; err = 507.72952675819397; time = 14.762600898742676\n",
      "Train: Epoch 5; err = 498.60830450057983; time = 14.773674964904785\n",
      "Train: Epoch 6; err = 493.34956181049347; time = 14.666167259216309\n",
      "Train: Epoch 7; err = 491.01311761140823; time = 14.751540184020996\n",
      "Train: Epoch 8; err = 484.1834804415703; time = 14.737906455993652\n",
      "Train: Epoch 9; err = 484.9392847418785; time = 14.846069812774658\n",
      "Train: Epoch 10; err = 478.6925780773163; time = 14.819225549697876\n",
      "Train: Epoch 11; err = 474.72894710302353; time = 14.771407127380371\n",
      "Train: Epoch 12; err = 471.5490748286247; time = 14.82361626625061\n",
      "Train: Epoch 13; err = 470.35122162103653; time = 14.724563121795654\n",
      "Train: Epoch 14; err = 467.4566590189934; time = 15.091293811798096\n",
      "0.00096\n",
      "tensor([0.1853, 0.1835, 0.6312], device='cuda:0', grad_fn=<MeanBackward1>) 0.8741095066070557\n",
      "Train: Epoch 15; err = 465.7873447537422; time = 14.769551992416382\n",
      "Train: Epoch 16; err = 462.7500081062317; time = 14.709810972213745\n",
      "Train: Epoch 17; err = 462.7319455742836; time = 14.75666069984436\n",
      "Train: Epoch 18; err = 458.8422785997391; time = 14.740672588348389\n",
      "Train: Epoch 19; err = 457.5153674483299; time = 14.691912174224854\n",
      "Train: Epoch 20; err = 456.76780104637146; time = 14.689756393432617\n",
      "Train: Epoch 21; err = 455.18085116147995; time = 14.710421085357666\n",
      "Train: Epoch 22; err = 455.5158578157425; time = 14.720807790756226\n",
      "Train: Epoch 23; err = 453.4301232099533; time = 14.614223957061768\n",
      "Train: Epoch 24; err = 449.8886584639549; time = 14.645349264144897\n",
      "Train: Epoch 25; err = 451.17691242694855; time = 14.768007755279541\n",
      "Train: Epoch 26; err = 455.7535329461098; time = 14.678906202316284\n",
      "Train: Epoch 27; err = 447.657463490963; time = 14.62637996673584\n",
      "Train: Epoch 28; err = 443.63807731866837; time = 14.615276336669922\n",
      "Train: Epoch 29; err = 442.65212082862854; time = 14.714972972869873\n",
      "0.0009216\n",
      "tensor([0.1328, 0.1237, 0.7435], device='cuda:0', grad_fn=<MeanBackward1>) 0.7843515276908875\n",
      "Train: Epoch 30; err = 443.3960486650467; time = 14.639343023300171\n",
      "Train: Epoch 31; err = 440.5996016263962; time = 14.621232986450195\n",
      "Train: Epoch 32; err = 438.36476999521255; time = 14.611080169677734\n",
      "Train: Epoch 33; err = 440.6561737060547; time = 14.713141441345215\n",
      "Train: Epoch 34; err = 436.68379932641983; time = 14.746493101119995\n",
      "Train: Epoch 35; err = 435.9383260011673; time = 14.820142984390259\n",
      "Train: Epoch 36; err = 435.64307260513306; time = 14.652271270751953\n",
      "Train: Epoch 37; err = 434.5650480389595; time = 14.652541160583496\n",
      "Train: Epoch 38; err = 431.2525342106819; time = 14.669750690460205\n",
      "Train: Epoch 39; err = 432.702918112278; time = 14.651636362075806\n",
      "Train: Epoch 40; err = 430.9161661863327; time = 14.618679523468018\n",
      "Train: Epoch 41; err = 428.66326785087585; time = 14.667882204055786\n",
      "Train: Epoch 42; err = 428.7137618660927; time = 14.74777889251709\n",
      "Train: Epoch 43; err = 427.5143073797226; time = 14.639341831207275\n",
      "Train: Epoch 44; err = 427.20485615730286; time = 14.62484335899353\n",
      "0.0008847359999999999\n",
      "tensor([0.1068, 0.0654, 0.8278], device='cuda:0', grad_fn=<MeanBackward1>) 0.6998815536499023\n",
      "Train: Epoch 45; err = 421.7327125072479; time = 14.618882894515991\n",
      "Train: Epoch 46; err = 421.50541466474533; time = 14.66769003868103\n",
      "Train: Epoch 47; err = 419.4672327041626; time = 14.614050149917603\n",
      "Train: Epoch 48; err = 420.7109042406082; time = 14.611420392990112\n",
      "Train: Epoch 49; err = 417.71148031949997; time = 14.650184154510498\n",
      "Train: Epoch 50; err = 417.96523201465607; time = 14.723784446716309\n",
      "Train: Epoch 51; err = 415.2245469093323; time = 14.762206554412842\n",
      "Train: Epoch 52; err = 417.37765634059906; time = 14.643761396408081\n",
      "Train: Epoch 53; err = 415.7544382214546; time = 14.641318559646606\n",
      "Train: Epoch 54; err = 414.65784019231796; time = 14.634945154190063\n",
      "Train: Epoch 55; err = 413.49943059682846; time = 14.674494504928589\n",
      "Train: Epoch 56; err = 415.7567877173424; time = 14.642595291137695\n",
      "Train: Epoch 57; err = 412.1500568985939; time = 14.642019987106323\n",
      "Train: Epoch 58; err = 410.7717346549034; time = 14.686012268066406\n",
      "Train: Epoch 59; err = 411.61421632766724; time = 14.75442361831665\n",
      "0.0008493465599999999\n",
      "tensor([0.1354, 0.0738, 0.7908], device='cuda:0', grad_fn=<MeanBackward1>) 0.7380672693252563\n",
      "Train: Epoch 60; err = 411.8639445900917; time = 14.64611554145813\n",
      "Train: Epoch 61; err = 409.18427217006683; time = 14.614717721939087\n",
      "Train: Epoch 62; err = 408.75443863868713; time = 14.652804613113403\n",
      "Train: Epoch 63; err = 408.59165918827057; time = 14.639911651611328\n",
      "Train: Epoch 64; err = 408.9808019399643; time = 14.635637760162354\n",
      "Train: Epoch 65; err = 407.7721808552742; time = 14.901946067810059\n",
      "Train: Epoch 66; err = 406.5795817375183; time = 14.790094375610352\n",
      "Train: Epoch 67; err = 405.36147183179855; time = 14.807302474975586\n",
      "Train: Epoch 68; err = 405.42730873823166; time = 14.719335794448853\n",
      "Train: Epoch 69; err = 404.329256772995; time = 14.660628318786621\n",
      "Train: Epoch 70; err = 404.34780353307724; time = 14.905157327651978\n",
      "Train: Epoch 71; err = 404.2469820380211; time = 14.831282377243042\n",
      "Train: Epoch 72; err = 403.1618813276291; time = 14.735172986984253\n",
      "Train: Epoch 73; err = 404.13327956199646; time = 14.71933627128601\n",
      "Train: Epoch 74; err = 401.9411385655403; time = 14.769367218017578\n",
      "0.0008153726975999999\n",
      "tensor([0.0522, 0.0862, 0.8615], device='cuda:0', grad_fn=<MeanBackward1>) 0.6775826215744019\n",
      "Train: Epoch 75; err = 402.59276980161667; time = 14.89442753791809\n",
      "Train: Epoch 76; err = 402.6165544986725; time = 14.79777455329895\n",
      "Train: Epoch 77; err = 400.5294478535652; time = 14.644196271896362\n",
      "Train: Epoch 78; err = 399.6014459133148; time = 14.666459321975708\n",
      "Train: Epoch 79; err = 400.5898907780647; time = 14.640408992767334\n",
      "Train: Epoch 80; err = 398.3863263130188; time = 14.657350063323975\n",
      "Train: Epoch 81; err = 399.70293337106705; time = 14.657549858093262\n",
      "Train: Epoch 82; err = 397.94412714242935; time = 14.644540309906006\n",
      "Train: Epoch 83; err = 397.92792451381683; time = 14.967981576919556\n",
      "Train: Epoch 84; err = 397.8807154893875; time = 15.175098657608032\n",
      "Train: Epoch 85; err = 396.6846235394478; time = 14.851647138595581\n",
      "Train: Epoch 86; err = 397.4913766384125; time = 15.500383615493774\n",
      "Train: Epoch 87; err = 396.2813194990158; time = 15.533530950546265\n",
      "Train: Epoch 88; err = 395.81320279836655; time = 15.532517671585083\n",
      "Train: Epoch 89; err = 394.27758264541626; time = 14.817844867706299\n",
      "0.0007827577896959998\n",
      "tensor([0.1107, 0.0940, 0.7953], device='cuda:0', grad_fn=<MeanBackward1>) 0.7279908061027527\n",
      "Train: Epoch 90; err = 394.3710057735443; time = 14.88301157951355\n",
      "Train: Epoch 91; err = 396.5320218205452; time = 15.39536166191101\n",
      "Train: Epoch 92; err = 392.84052842855453; time = 15.300839900970459\n",
      "Train: Epoch 93; err = 392.8605190515518; time = 15.479609251022339\n",
      "Train: Epoch 94; err = 392.54300928115845; time = 14.951825618743896\n",
      "Train: Epoch 95; err = 394.38344419002533; time = 15.011995792388916\n",
      "Train: Epoch 96; err = 395.533479988575; time = 15.25787615776062\n",
      "Train: Epoch 97; err = 390.74569100141525; time = 14.765953063964844\n",
      "Train: Epoch 98; err = 390.13142067193985; time = 14.717353582382202\n",
      "Train: Epoch 99; err = 392.2511388659477; time = 14.710191011428833\n",
      "Train: Epoch 100; err = 391.1277447938919; time = 14.612984895706177\n"
     ]
    }
   ],
   "source": [
    "_ = dev_color_mod.fit(dev_cols_train, dev_seqs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = dev_color_mod.predict(dev_cols_test, dev_seqs_test)\n",
    "#dev_color_mod.predict(dev_cols_test, dev_seqs_test, probabilities=True)\n",
    "train_preds = dev_color_mod.predict(dev_cols_train, dev_seqs_train)\n",
    "#dev_color_mod.predict(dev_cols_test, dev_seqs_test, probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 9213 / 11749 0.7841518427100179\n",
      "train 29932 / 35245 0.8492552135054617\n"
     ]
    }
   ],
   "source": [
    "correct = sum([1 if x == 2 else 0 for x in test_preds])\n",
    "print(\"test\", correct, \"/\", len(test_preds), correct/len(test_preds))\n",
    "correct = sum([1 if x == 2 else 0 for x in train_preds])\n",
    "print(\"train\", correct, \"/\", len(train_preds), correct/len(train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = {}\n",
    "for ex in dev_examples:\n",
    "    #ex.display(typ='speaker')\n",
    "    #print(ex.condition)\n",
    "    if ex.condition not in totals:\n",
    "        totals[ex.condition] = 0\n",
    "    totals[ex.condition]+=1\n",
    "    #print(dev_color_mod.predict([ex.speaker_context], [tokenize_example(ex.contents)], probabilities=True))\n",
    "    #print(dev_color_mod.predict([ex.speaker_context], [tokenize_example(ex.contents)])[0])\n",
    "    #print()\n",
    "    \n",
    "scores = {}\n",
    "preds = dev_color_mod.predict([represent_color_context(colors) for colors in dev_rawcols], \n",
    "                              [tokenize_example(text) for text in dev_texts])\n",
    "for i, ex in enumerate(dev_examples):\n",
    "    #ex.display(typ='speaker')\n",
    "    #print(ex.condition)\n",
    "    if ex.condition not in scores:\n",
    "        scores[ex.condition] = 0\n",
    "    if preds[i] == 2:\n",
    "        scores[ex.condition]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close : 11595 / 15519 = 0.7471486564855983\n",
      "far : 14583 / 15782 = 0.9240273729565328\n",
      "split : 12880 / 15693 = 0.8207481042503026\n"
     ]
    }
   ],
   "source": [
    "for condition in scores:\n",
    "    print(condition, \":\", scores[condition], \"/\", totals[condition], \"=\", scores[condition]/totals[condition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_perp = dev_color_mod.perplexities(dev_cols_test, dev_seqs_test)\n",
    "#dev_perp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_color_mod.save_model(\"literal_listener.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pickle():\n",
    "    import pickle \n",
    "\n",
    "    with open('dev_vocab.pickle', 'wb') as handle:\n",
    "        pickle.dump(dev_vocab, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('dev_seqs_test.pickle', 'wb') as handle:\n",
    "        pickle.dump(dev_seqs_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('dev_seqs_train.pickle', 'wb') as handle:\n",
    "        pickle.dump(dev_seqs_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('dev_cols_test.pickle', 'wb') as handle:\n",
    "        pickle.dump(dev_cols_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('dev_cols_train.pickle', 'wb') as handle:\n",
    "        pickle.dump(dev_cols_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('embedding.pickle', 'wb') as handle:\n",
    "        pickle.dump(embedding, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "save_to_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
