{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework and bake-off: pragmatic color descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Christopher Potts\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2020\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Overview](#Overview)\n",
    "1. [Set-up](#Set-up)\n",
    "1. [All two-word examples as a dev corpus](#All-two-word-examples-as-a-dev-corpus)\n",
    "1. [Dev dataset](#Dev-dataset)\n",
    "1. [Random train–test split for development](#Random-train–test-split-for-development)\n",
    "1. [Question 1: Improve the tokenizer [1 point]](#Question-1:-Improve-the-tokenizer-[1-point])\n",
    "1. [Use the tokenizer](#Use-the-tokenizer)\n",
    "1. [Question 2: Improve the color representations [1 point]](#Question-2:-Improve-the-color-representations-[1-point])\n",
    "1. [Use the color representer](#Use-the-color-representer)\n",
    "1. [Initial model](#Initial-model)\n",
    "1. [Question 3: GloVe embeddings [1 points]](#Question-3:-GloVe-embeddings-[1-points])\n",
    "1. [Try the GloVe representations](#Try-the-GloVe-representations)\n",
    "1. [Question 4: Color context [3 points]](#Question-4:-Color-context-[3-points])\n",
    "1. [Your original system [3 points]](#Your-original-system-[3-points])\n",
    "1. [Bakeoff [1 point]](#Bakeoff-[1-point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This homework and associated bake-off are oriented toward building an effective system for generating color descriptions that are pragmatic in the sense that they would help a reader/listener figure out which color was being referred to in a shared context consisting of a target color (whose identity is known only to the describer/speaker) and a set of distractors.\n",
    "\n",
    "The notebook [colors_overview.ipynb](colors_overview.ipynb) should be studied before work on this homework begins. That notebook provides backgroud on the task, the dataset, and the modeling code that you will be using and adapting.\n",
    "\n",
    "The homework questions are more open-ended than previous ones have been. Rather than asking you to implement pre-defined functionality, they ask you to try to improve baseline components of the full system in ways that you find to be effective. As usual, this culiminates in a prompt asking you to develop a novel system for entry into the bake-off. In this case, though, the work you do for the homework will likely be directly incorporated into that system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [colors_overview.ipynb](colors_overview.ipynb) for set-up in instructions and other background details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colors import ColorsCorpusReader\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_color_selector import (\n",
    "    ColorizedNeuralListener, create_example_dataset)\n",
    "from torch_color_describer import (\n",
    "    ColorizedInputDescriber, create_example_dataset)\n",
    "import utils\n",
    "from utils import START_SYMBOL, END_SYMBOL, UNK_SYMBOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.fix_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS_SRC_FILENAME = os.path.join(\n",
    "    \"data\", \"colors\", \"filteredCorpus.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All two-word examples as a dev corpus\n",
    "\n",
    "So that you don't have to sit through excessively long training runs during development, I suggest working with the two-word-only subset of the corpus until you enter into the late stages of system testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_corpus = ColorsCorpusReader(\n",
    "    COLORS_SRC_FILENAME, \n",
    "    word_count=None, \n",
    "    normalize_colors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_examples = list(dev_corpus.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This subset has about one-third the examples of the full corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46994"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We __should__ worry that it's not a fully representative sample. Most of the descriptions in the full corpus are shorter, and a large proportion are longer. So this dataset is mainly for debugging, development, and general hill-climbing. All findings should be validated on the full dataset at some point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev dataset\n",
    "\n",
    "The first step is to extract the raw color and raw texts from the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_pickle():\n",
    "    import pickle \n",
    "    with open('dev_vocab_speaker.pickle', 'rb') as handle:\n",
    "        dev_vocab = pickle.load(handle)\n",
    "    with open('dev_vocab_listener.pickle', 'rb') as handle:\n",
    "        dev_vocab_listener = pickle.load(handle)\n",
    "    with open('dev_seqs_test.pickle', 'rb') as handle:\n",
    "        dev_seqs_test = pickle.load(handle)\n",
    "    with open('dev_seqs_train_speaker.pickle', 'rb') as handle:\n",
    "        dev_seqs_train = pickle.load(handle)\n",
    "    with open('dev_cols_test.pickle', 'rb') as handle:\n",
    "        dev_cols_test = pickle.load(handle)\n",
    "    with open('dev_cols_train_speaker.pickle', 'rb') as handle:\n",
    "        dev_cols_train = pickle.load(handle)\n",
    "    with open('dev_glove_vocab.pickle', 'rb') as handle:\n",
    "        dev_glove_vocab = pickle.load(handle)\n",
    "    with open('dev_glove_embedding.pickle', 'rb') as handle:\n",
    "        dev_glove_embedding = pickle.load(handle)\n",
    "    with open('embedding.pickle', 'rb') as handle:\n",
    "        embedding = pickle.load(handle)\n",
    "    return dev_vocab, dev_vocab_listener, dev_seqs_test, dev_seqs_train, dev_cols_test, dev_cols_train, \\\n",
    "dev_glove_vocab, dev_glove_embedding, embedding\n",
    "dev_vocab, dev_vocab_listener, dev_seqs_test, dev_seqs_train, dev_cols_test, dev_cols_train, dev_glove_vocab, \\\n",
    "dev_glove_embedding, embedding = load_from_pickle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literal speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_color_seqs, toy_word_seqs, toy_vocab = create_example_dataset(\n",
    "    group_size=50, vec_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_color_seqs_train, toy_color_seqs_test, toy_word_seqs_train, toy_word_seqs_test = \\\n",
    "    train_test_split(toy_color_seqs, toy_word_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "toy_mod = ColorizedInputDescriber(\n",
    "    toy_vocab, \n",
    "    embed_dim=10, \n",
    "    hidden_dim=100, \n",
    "    max_iter=10, \n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0; train err = 1.6312565803527832; time = 0.3290736675262451\n",
      "Epoch 1; train err = 1.5512980222702026; time = 0.023005247116088867\n",
      "Epoch 2; train err = 1.4668164253234863; time = 0.023005008697509766\n",
      "Epoch 3; train err = 1.355759859085083; time = 0.02200460433959961\n",
      "Epoch 4; train err = 1.2426749467849731; time = 0.023005247116088867\n",
      "Epoch 5; train err = 1.1513525247573853; time = 0.02200484275817871\n",
      "Epoch 6; train err = 1.1144208908081055; time = 0.022995471954345703\n",
      "Epoch 7; train err = 1.0158658027648926; time = 0.02200460433959961\n",
      "Epoch 8; train err = 0.9626907110214233; time = 0.023005008697509766\n",
      "Epoch 9; train err = 0.8614288568496704; time = 0.021996021270751953\n"
     ]
    }
   ],
   "source": [
    "_ = toy_mod.fit(toy_color_seqs_train, toy_word_seqs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7368421052631579"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_mod.listener_accuracy(toy_color_seqs_test, toy_word_seqs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that worked, then you can now try this model on SCC problems!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "literal_listener_listener = ColorizedNeuralListener(\n",
    "    dev_vocab_listener, \n",
    "    #embedding=dev_glove_embedding, \n",
    "    embed_dim=100,\n",
    "    embedding=embedding,\n",
    "    hidden_dim=100, \n",
    "    max_iter=100,\n",
    "    batch_size=256,\n",
    "    dropout_prob=0.,\n",
    "    eta=0.001,\n",
    "    lr_rate=0.96,\n",
    "    warm_start=True,\n",
    "    device='cuda')\n",
    "literal_listener_listener.load_model(\"literal_listener_with_attention_listener_split.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "dev_color_mod = ColorizedInputDescriber(\n",
    "    dev_glove_vocab, \n",
    "    embedding=dev_glove_embedding, \n",
    "    hidden_dim=100, \n",
    "    max_iter=5, \n",
    "    eta=0.0005,\n",
    "    batch_size=32,\n",
    "    warm_start=True)\n",
    "#dev_color_mod.load_model(\"literal_speaker.pt\")\n",
    "#dev_color_mod.warm_start=True\n",
    "#dev_color_mod.opt = dev_color_mod.optimizer(\n",
    "#                dev_color_mod.model.parameters(),\n",
    "#                lr=dev_color_mod.eta,\n",
    "#                weight_decay=dev_color_mod.l2_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_performance(speaker, listener, cols):\n",
    "    speaker_preds_test = speaker.predict(cols)\n",
    "    listened_preds = listener.predict(cols, speaker_preds_test)\n",
    "    correct = sum([1 if x == 2 else 0 for x in listened_preds])\n",
    "    print(\"test\", correct, \"/\", len(listened_preds), correct/len(listened_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45; train err = 332.3955352306366; time = 12.813606023788452\n",
      "Epoch 46; train err = 334.60132697224617; time = 13.113934516906738\n",
      "Epoch 47; train err = 330.8800345361233; time = 13.065903902053833\n",
      "Epoch 48; train err = 326.39075142145157; time = 14.95833444595337\n",
      "Epoch 49; train err = 322.96645595133305; time = 15.567483186721802\n",
      "test 9864 / 11749 0.8395608136862712\n",
      "Epoch 50; train err = 325.7755722999573; time = 15.631486177444458\n",
      "Epoch 51; train err = 326.77504739165306; time = 15.681498050689697\n",
      "Epoch 52; train err = 323.1483790129423; time = 15.379430294036865\n",
      "Epoch 53; train err = 319.0581514984369; time = 15.963561534881592\n",
      "Epoch 54; train err = 320.0287114083767; time = 15.819517850875854\n",
      "test 9959 / 11749 0.8476466082219763\n",
      "Epoch 55; train err = 319.82313945889473; time = 15.365428447723389\n",
      "Epoch 56; train err = 315.4929445683956; time = 16.141589641571045\n",
      "Epoch 57; train err = 314.95708388090134; time = 15.940555572509766\n",
      "Epoch 58; train err = 315.3841543495655; time = 15.31442666053772\n",
      "Epoch 59; train err = 314.85436299443245; time = 15.545457363128662\n",
      "test 9919 / 11749 0.844242063154311\n",
      "Epoch 60; train err = 313.5524640381336; time = 15.22839617729187\n",
      "Epoch 61; train err = 310.1512788236141; time = 15.435453653335571\n",
      "Epoch 62; train err = 313.39463645219803; time = 15.486465215682983\n",
      "Epoch 63; train err = 311.74936562776566; time = 15.269415378570557\n",
      "Epoch 64; train err = 309.86410892009735; time = 15.636498928070068\n",
      "test 9924 / 11749 0.8446676312877692\n",
      "Epoch 65; train err = 308.86254957318306; time = 15.55848240852356\n",
      "Epoch 66; train err = 304.5203858613968; time = 16.012572288513184\n",
      "Epoch 67; train err = 304.9009090512991; time = 15.716506242752075\n",
      "Epoch 68; train err = 304.81596417725086; time = 15.310415267944336\n",
      "Epoch 69; train err = 302.39388377964497; time = 15.033353567123413\n",
      "test 9942 / 11749 0.8461996765682186\n",
      "Epoch 70; train err = 301.36866645514965; time = 15.707513332366943\n",
      "Epoch 71; train err = 301.47156043350697; time = 15.894534587860107\n",
      "Epoch 72; train err = 300.40250328183174; time = 15.224406242370605\n",
      "Epoch 73; train err = 299.9284359663725; time = 15.79153299331665\n",
      "Epoch 74; train err = 300.122841745615; time = 14.910337209701538\n",
      "test 9896 / 11749 0.8422844497404034\n",
      "Epoch 75; train err = 298.8566548079252; time = 15.953559160232544\n",
      "Epoch 76; train err = 299.28464248776436; time = 15.965561389923096\n",
      "Epoch 77; train err = 295.28138822317123; time = 15.530453205108643\n",
      "Epoch 78; train err = 295.5684757530689; time = 14.752301692962646\n",
      "Epoch 79; train err = 293.33039693534374; time = 14.871315956115723\n",
      "test 9953 / 11749 0.8471359264618266\n",
      "Epoch 80; train err = 294.4158118367195; time = 16.09260106086731\n",
      "Epoch 81; train err = 292.47355565428734; time = 15.341422080993652\n",
      "Epoch 82; train err = 289.6169983893633; time = 14.764294624328613\n",
      "Epoch 83; train err = 288.00900945067406; time = 14.868316650390625\n",
      "Epoch 84; train err = 291.4791441112757; time = 14.870316982269287\n",
      "test 9999 / 11749 0.8510511532896416\n",
      "Epoch 85; train err = 290.53907515108585; time = 15.490455865859985\n",
      "Epoch 86; train err = 286.3678456246853; time = 15.526474237442017\n",
      "Epoch 87; train err = 285.15040150284767; time = 16.206615209579468\n",
      "Epoch 88; train err = 290.5950564146042; time = 15.951558351516724\n",
      "Epoch 89; train err = 283.9839521199465; time = 15.114379644393921\n",
      "test 10023 / 11749 0.8530938803302409\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    dev_color_mod.fit(dev_cols_train, dev_seqs_train)\n",
    "    \n",
    "    calc_performance(dev_color_mod, literal_listener_listener, dev_cols_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Github\\cs224u\\torch_color_describer.py:890: RuntimeWarning: divide by zero encountered in power\n",
      "  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8085794535705166"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_color_mod.listener_accuracy(dev_cols_test, dev_seqs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1630750132721086"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_perp = dev_color_mod.perplexities(dev_cols_test, dev_seqs_test)\n",
    "dev_perp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_color_mod.save_model('literal_speaker.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
