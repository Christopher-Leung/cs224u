{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listener-Hallucinating Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Christopher Leung\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2020\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [colors_overview.ipynb](colors_overview.ipynb) for set-up in instructions and other background details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colors import ColorsCorpusReader\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_color_selector import (\n",
    "    ColorizedNeuralListener, create_example_dataset)\n",
    "from torch_listener_with_attention import (\n",
    "    AttentionalColorizedNeuralListener, create_example_dataset)\n",
    "from torch_color_describer import ColorizedInputDescriber\n",
    "import utils\n",
    "from utils import START_SYMBOL, END_SYMBOL, UNK_SYMBOL\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.fix_random_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev dataset\n",
    "\n",
    "Let's load the saved training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_pickle():\n",
    "    import pickle \n",
    "    \n",
    "    with open('dev_vocab.pickle', 'rb') as handle:\n",
    "        dev_vocab = pickle.load(handle)\n",
    "    with open('dev_vocab_speaker.pickle', 'rb') as handle:\n",
    "        dev_vocab_speaker = pickle.load(handle)\n",
    "    with open('dev_vocab_listener.pickle', 'rb') as handle:\n",
    "        dev_vocab_listener = pickle.load(handle)\n",
    "    with open('dev_seqs_test.pickle', 'rb') as handle:\n",
    "        dev_seqs_test = pickle.load(handle)\n",
    "    with open('dev_seqs_train.pickle', 'rb') as handle:\n",
    "        dev_seqs_train = pickle.load(handle)\n",
    "    with open('dev_seqs_train_listener.pickle', 'rb') as handle:\n",
    "        dev_seqs_train_listener = pickle.load(handle)\n",
    "    with open('dev_seqs_train_speaker.pickle', 'rb') as handle:\n",
    "        dev_seqs_train_speaker = pickle.load(handle)\n",
    "    with open('dev_cols_test.pickle', 'rb') as handle:\n",
    "        dev_cols_test = pickle.load(handle)\n",
    "    with open('dev_cols_train.pickle', 'rb') as handle:\n",
    "        dev_cols_train = pickle.load(handle)\n",
    "    with open('dev_cols_train_listener.pickle', 'rb') as handle:\n",
    "        dev_cols_train_listener = pickle.load(handle)\n",
    "    with open('dev_cols_train_speaker.pickle', 'rb') as handle:\n",
    "        dev_cols_train_speaker = pickle.load(handle)\n",
    "    with open('dev_examples_test.pickle', 'rb') as handle:\n",
    "        dev_examples_test = pickle.load(handle)\n",
    "    with open('embedding.pickle', 'rb') as handle:\n",
    "        embedding = pickle.load(handle)\n",
    "    return dev_vocab, dev_vocab_speaker, dev_vocab_listener, dev_seqs_test, dev_seqs_train, dev_seqs_train_speaker, \\\n",
    "dev_seqs_train_listener, dev_cols_test, dev_cols_train, dev_cols_train_speaker, dev_cols_train_listener, dev_examples_test, \\\n",
    "embedding\n",
    "\n",
    "dev_vocab, dev_vocab_speaker, dev_vocab_listener, dev_seqs_test, dev_seqs_train, dev_seqs_train_speaker, \\\n",
    "dev_seqs_train_listener, dev_cols_test, dev_cols_train, dev_cols_train_speaker, dev_cols_train_listener, \\\n",
    "dev_examples_test, embedding = load_from_pickle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe embeddings\n",
    "\n",
    "We also load the GloVe embedding that was used by the speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_from_pickle():\n",
    "    import pickle \n",
    "    with open('dev_glove_vocab.pickle', 'rb') as handle:\n",
    "        dev_glove_vocab = pickle.load(handle)\n",
    "    with open('dev_glove_embedding.pickle', 'rb') as handle:\n",
    "        dev_glove_embedding = pickle.load(handle)\n",
    "    return dev_glove_vocab, dev_glove_embedding\n",
    "dev_glove_vocab, dev_glove_embedding = load_glove_from_pickle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Literal Listener trained on Listener Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "literal_listener_listener = ColorizedNeuralListener(\n",
    "    dev_vocab_listener, \n",
    "    #embedding=dev_glove_embedding, \n",
    "    embed_dim=100,\n",
    "    embedding=embedding,\n",
    "    hidden_dim=100, \n",
    "    max_iter=100,\n",
    "    batch_size=256,\n",
    "    dropout_prob=0.,\n",
    "    eta=0.001,\n",
    "    lr_rate=0.96,\n",
    "    warm_start=True,\n",
    "    device='cuda')\n",
    "literal_listener_listener.load_model(\"literal_listener_with_attention_listener_split.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Literal Listener trained on Speaker Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "literal_listener_speaker = ColorizedNeuralListener(\n",
    "    dev_vocab_speaker, \n",
    "    #embedding=dev_glove_embedding, \n",
    "    embed_dim=100,\n",
    "    embedding=embedding,\n",
    "    hidden_dim=100, \n",
    "    max_iter=100,\n",
    "    batch_size=256,\n",
    "    dropout_prob=0.,\n",
    "    eta=0.001,\n",
    "    lr_rate=0.96,\n",
    "    warm_start=True,\n",
    "    device='cuda')\n",
    "literal_listener_speaker.load_model(\"literal_listener_with_attention_speaker_split.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Literal Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "literal_speaker = ColorizedInputDescriber(\n",
    "    dev_glove_vocab, \n",
    "    embedding=dev_glove_embedding, \n",
    "    hidden_dim=100, \n",
    "    max_iter=40, \n",
    "    eta=0.0005,\n",
    "    batch_size=32)\n",
    "literal_speaker.load_model(\"literal_speaker.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hallucinating Pragmatic Speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We coin the Hallucinating Pragmatic Speaker to be the speaker that takes the k highest probability utterances that describes the context by the literal speaker, which then is filtered again by taking the top m number of utterances which maximize the literal listener likelihood of selecting the correct color.\n",
    "\n",
    "On a high level, the idea here is that the speaker is producing candidate utterances that it thinks is gramatically correct, while picking the top m utterances that maximizes understanding to the communicant. We will refer to this as utterances as hallucinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_listener_hallucinations(input_colors, \\\n",
    "                                     speaker, \n",
    "                                     listener, \n",
    "                                     num_hallucinations=1, \n",
    "                                     alpha=0, \n",
    "                                     m_samples=3, \n",
    "                                     k_samples=6,\n",
    "                                     speaker_preference=0.5,\n",
    "                                     max_length=20,\n",
    "                                     batch_size=1000):\n",
    "    '''This method generates listener hallucinations.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_colors:\n",
    "        A list of size (n,m,p) of int where each example has a list of m colors. Each color\n",
    "        is embedded in size p.\n",
    "    Returns\n",
    "    -------\n",
    "    prag_speaker_pred:\n",
    "        (n,k_samples,*) The top sentences from the speaker that maximizes the likelihood \n",
    "        that the listener will choose the target color. Each sentence can be of different\n",
    "        length and is tokenized.\n",
    "    '''\n",
    "    assert(num_hallucinations <= m_samples)\n",
    "    print(\"Sampling utterances\")\n",
    "    #utterances, speaker_probs = speaker.sample_utterances(input_colors, k_samples=k_samples)\n",
    "    utterances, speaker_probs = \\\n",
    "        speaker.sample_utterances_with_listener(listener, \\\n",
    "                                                input_colors, \\\n",
    "                                                k_samples=k_samples, \\\n",
    "                                                m_samples=m_samples, \\\n",
    "                                                max_length=max_length, \\\n",
    "                                                batch_size=batch_size, \\\n",
    "                                                speaker_preference=speaker_preference) \n",
    "        #speaker.sample_utterances_with_listener(listener, input_colors, k_samples=k_samples, m_samples=num_hallucinations)\n",
    "    \n",
    "    print(\"Preparing Data\")\n",
    "    # Prepare data, flatten the target utterances and repeat the input colors per k_sample\n",
    "    target_utterances = [seq for seq_list in utterances for seq in seq_list]\n",
    "    input_colors_extended = [item for item in input_colors for i in range(m_samples)]\n",
    "    \n",
    "    print(\"Calculating probabilities\")\n",
    "    utterance_probs = listener.predict(input_colors_extended, target_utterances, probabilities=True)\n",
    "    utterance_probs = torch.FloatTensor([preds[2] for preds in utterance_probs]).view(-1, m_samples).to(speaker.device)\n",
    "    #utterance_probs = utterance_probs ** alpha\n",
    "    \n",
    "    #total = torch.sum(utterance_probs, dim=1).unsqueeze(1)\n",
    "    #normalized_utterance_probs = utterance_probs/total\n",
    "    normalized_utterance_probs = alpha*torch.log(speaker_probs.view(-1, m_samples)+1e-12) + \\\n",
    "                                 (1.-alpha)*torch.log(utterance_probs+1e-12)\n",
    "    #normalized_utterance_probs = torch.FloatTensor(utterance_probs).view(-1, m_samples).to(speaker.device)\n",
    "    \n",
    "    print(\"Finding top m utterances\")\n",
    "    # Find the best k number of utterances that maximize the listener likelihood\n",
    "    best_utter_values, best_utter_indices = torch.topk(normalized_utterance_probs, num_hallucinations, dim=1)\n",
    "    \n",
    "    # Index into the utterances to find the sequence candidates\n",
    "    for ind, seqs in enumerate(utterances):\n",
    "        for utter_index in best_utter_indices[ind]:\n",
    "            if utter_index >= len(seqs) or utter_index < 0:\n",
    "                print(\"index oob\", best_utter_indices[ind].item(), best_utter_values[ind].item(), ind)\n",
    "                print(normalized_utterance_probs.view(-1, m_samples)[ind])\n",
    "                print(torch.log(utterance_probs+1e-12)[ind])\n",
    "                \n",
    "    prag_speaker_pred = [[seqs[utter_index] for utter_index in \\\n",
    "                          best_utter_indices[ind]] for ind, seqs in enumerate(utterances)]\n",
    "    return prag_speaker_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_performance(speaker, listener, cols):\n",
    "    torch.cuda.empty_cache()\n",
    "    speaker_preds_test = speaker.predict(cols)\n",
    "    listened_preds = listener.predict(cols, speaker_preds_test)\n",
    "    correct = sum([1 if x == 2 else 0 for x in listened_preds])\n",
    "    print(\"test\", correct, \"/\", len(listened_preds), correct/len(listened_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking the L_0 and S_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speaker_preds_test = literal_speaker.predict(dev_cols_test)\n",
    "#listened_preds = literal_listener_listener.predict(dev_cols_test, speaker_preds_test)\n",
    "#correct = sum([1 if x == 2 else 0 for x in listened_preds])\n",
    "#print(\"test\", correct, \"/\", len(listened_preds), correct/len(listened_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Listener-Hallucinating Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "listener_hallucinating_speaker = ColorizedInputDescriber(\n",
    "    dev_glove_vocab, \n",
    "    embedding=dev_glove_embedding, \n",
    "    hidden_dim=100, \n",
    "    max_iter=40, \n",
    "    eta=0.0005,\n",
    "    batch_size=32,\n",
    "    warm_start=True)\n",
    "listener_hallucinating_speaker.load_model(\"literal_speaker.pt\")\n",
    "num_hallucinations = 1\n",
    "# load the old one\n",
    "#listener_hallucinating_speaker.load_model(\"listener_hallucinating_speaker.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener_hallucinating_speaker.warm_start=True\n",
    "listener_hallucinating_speaker.opt = listener_hallucinating_speaker.optimizer(\n",
    "                listener_hallucinating_speaker.model.parameters(),\n",
    "                lr=listener_hallucinating_speaker.eta,\n",
    "                weight_decay=listener_hallucinating_speaker.l2_strength)\n",
    "listener_hallucinating_speaker.max_iter=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling utterances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Github\\cs224u\\torch_color_describer.py:657: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  color_seqs = torch.FloatTensor(color_seqs).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 / 18\n",
      "Processing batch 2 / 18\n",
      "Processing batch 3 / 18\n",
      "Processing batch 4 / 18\n",
      "Processing batch 5 / 18\n",
      "Processing batch 6 / 18\n",
      "Processing batch 7 / 18\n",
      "Processing batch 8 / 18\n",
      "Processing batch 9 / 18\n",
      "Processing batch 10 / 18\n",
      "Processing batch 11 / 18\n",
      "Processing batch 12 / 18\n",
      "Processing batch 13 / 18\n",
      "Processing batch 14 / 18\n",
      "Processing batch 15 / 18\n",
      "Processing batch 16 / 18\n",
      "Processing batch 17 / 18\n",
      "Processing batch 18 / 18\n",
      "Preparing Data\n",
      "Calculating probabilities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Github\\cs224u\\torch_color_selector.py:77: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  color_seqs = torch.FloatTensor(color_seqs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'speaker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-93ee17454e78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                                                               \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                                                                               \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                                                                               speaker_preference=0.5)\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#utterances, speaker_probs = \\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Github\\cs224u\\torch_color_describer.py\u001b[0m in \u001b[0;36mgenerate_listener_hallucinations\u001b[1;34m(self, input_colors, listener, num_hallucinations, alpha, m_samples, k_samples, speaker_preference, max_length, batch_size)\u001b[0m\n\u001b[0;32m   1124\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Calculating probabilities\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m         \u001b[0mutterance_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_colors_extended\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_utterances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1126\u001b[1;33m         \u001b[0mutterance_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mutterance_probs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeaker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1127\u001b[0m         \u001b[1;31m#utterance_probs = utterance_probs ** alpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'speaker' is not defined"
     ]
    }
   ],
   "source": [
    "m_samples = 3\n",
    "dataset = dev_cols_train_speaker\n",
    "utterances = listener_hallucinating_speaker.generate_listener_augmentations(dataset, \\\n",
    "                                                                              literal_listener_speaker,\n",
    "                                                                              num_hallucinations=num_hallucinations,\n",
    "                                                                              k_samples=6, \n",
    "                                                                              m_samples=m_samples, \n",
    "                                                                              batch_size=1000, \n",
    "                                                                              max_length=12,\n",
    "                                                                              alpha=1.,\n",
    "                                                                              speaker_preference=0.5)\n",
    "\n",
    "#utterances, speaker_probs = \\\n",
    "#        listener_hallucinating_speaker.sample_utterances_with_listener(literal_listener_speaker, \\\n",
    "#                                                                       dev_cols_train_speaker, \\\n",
    "#                                                                       k_samples=6, \\\n",
    "#                                                                       m_samples=m_samples, \\\n",
    "#                                                                       max_length=12, \\\n",
    "#                                                                       batch_size=1000, \\\n",
    "#                                                                      speaker_preference=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten\n",
    "top_hallucinations = [seq for seqs in utterances for seq in seqs]\n",
    "#top_hallucinations = utterances\n",
    "dev_cols_train_speaker_extended = [cols for cols in dataset for i in range(num_hallucinations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(top_hallucinations))\n",
    "print(len(dev_cols_train_speaker_extended))\n",
    "print(top_hallucinations[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listened_preds = literal_listener_speaker.predict(dev_cols_train_speaker_extended, top_hallucinations)\n",
    "correct = sum([1 if x == 2 else 0 for x in listened_preds])\n",
    "print(\"test\", correct, \"/\", len(listened_preds), correct/len(listened_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    listener_hallucinating_speaker.fit(dev_cols_train_speaker_extended, top_hallucinations)\n",
    "    \n",
    "    calc_performance(listener_hallucinating_speaker, literal_listener_listener, dev_cols_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also train S_0 for extra epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "literal_speaker.warm_start=True\n",
    "literal_speaker.opt = literal_speaker.optimizer(\n",
    "                literal_speaker.model.parameters(),\n",
    "                lr=literal_speaker.eta,\n",
    "                weight_decay=literal_speaker.l2_strength)\n",
    "literal_speaker.max_iter=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    literal_speaker.fit(dev_cols_train_speaker, dev_seqs_train_speaker)\n",
    "    \n",
    "    calc_performance(literal_speaker, literal_listener_listener, dev_cols_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  S_1 utterances are longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_1_utt = listener_hallucinating_speaker.predict(dev_cols_test)\n",
    "#S_1_utt, S_1_scores = \\\n",
    "#        listener_hallucinating_speaker.sample_utterances_with_listener(literal_listener_speaker, \\\n",
    "#                                                                       dev_cols_test[:12], \\\n",
    "#                                                                       k_samples=6, \\\n",
    "#                                                                       m_samples=3, \\\n",
    "#                                                                       max_length=20, \\\n",
    "#                                                                       batch_size=5)\n",
    "S_0_utt = literal_speaker.predict(dev_cols_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for example_ind in range(len(dev_examples_test)):\n",
    "    if len(S_1_utt[example_ind]) > 6:\n",
    "        print(dev_examples_test[example_ind].condition)\n",
    "        dev_examples_test[example_ind].display(typ='speaker')\n",
    "        print(example_ind,\"S_1:\",\" \".join(S_1_utt[example_ind][1:-1]))\n",
    "        print(example_ind,\"S_0:\",\" \".join(S_0_utt[example_ind][1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_ind = 303                                                                                               \n",
    "\n",
    "print(\"condition:\",dev_examples_test[example_ind].condition)\n",
    "print(\"human:\",end=' ')\n",
    "dev_examples_test[example_ind].display(typ='speaker')\n",
    "print(\"S_1:\",\" \".join(S_1_utt[example_ind][1:-1]))\n",
    "print(\"S_0:\",\" \".join(S_0_utt[example_ind][1:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts of grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_per_condition_s0 = {}\n",
    "negatives_per_condition_s0 = {}\n",
    "comparatives_per_condition_s0 = {}\n",
    "superlatives_per_condition_s0 = {}\n",
    "formatives_per_condition_s0 = {}\n",
    "lengths_per_condition_s1 = {}\n",
    "negatives_per_condition_s1 = {}\n",
    "comparatives_per_condition_s1 = {}\n",
    "superlatives_per_condition_s1 = {}\n",
    "formatives_per_condition_s1 = {}\n",
    "lengths_per_condition_human = {}\n",
    "negatives_per_condition_human = {}\n",
    "comparatives_per_condition_human = {}\n",
    "superlatives_per_condition_human = {}\n",
    "formatives_per_condition_human = {}\n",
    "totals_per_condition = {}\n",
    "for condition in [\"far\", \"close\", \"split\"]:\n",
    "    lengths_per_condition_s0[condition] = 0\n",
    "    negatives_per_condition_s0[condition] = 0\n",
    "    comparatives_per_condition_s0[condition] = 0\n",
    "    superlatives_per_condition_s0[condition] = 0\n",
    "    formatives_per_condition_s0[condition] = 0\n",
    "    lengths_per_condition_s1[condition] = 0\n",
    "    negatives_per_condition_s1[condition] = 0\n",
    "    comparatives_per_condition_s1[condition] = 0\n",
    "    superlatives_per_condition_s1[condition] = 0\n",
    "    formatives_per_condition_s1[condition] = 0\n",
    "    lengths_per_condition_human[condition] = 0\n",
    "    negatives_per_condition_human[condition] = 0\n",
    "    comparatives_per_condition_human[condition] = 0\n",
    "    superlatives_per_condition_human[condition] = 0\n",
    "    formatives_per_condition_human[condition] = 0\n",
    "    totals_per_condition[condition] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_seq_without_turns(utt):\n",
    "    filtered_list = list(filter(lambda x: x not in ['#', '###', ',', '.','!','?','(',')','%',':',';'], utt[1:-1]))\n",
    "    prev_word = \"\"\n",
    "    for i in range(len(filtered_list)):\n",
    "        if i >= len(filtered_list):\n",
    "            continue\n",
    "        cur_word = filtered_list[i]\n",
    "        if cur_word in [\"+er\", \"+est\", \"+ish\"]:\n",
    "            word = prev_word + cur_word[1:]\n",
    "            if i == 0:\n",
    "                filtered_list[i] = word\n",
    "            else:\n",
    "                filtered_list[i-1] = word\n",
    "                del filtered_list[i]\n",
    "                i = i-1\n",
    "    return filtered_list\n",
    "\n",
    "for example_ind in range(len(S_1_utt)):\n",
    "    condition = dev_examples_test[example_ind].condition\n",
    "    \n",
    "    if len(list(set([\"+er\"]) & set(S_1_utt[example_ind]))) > 0:\n",
    "        comparatives_per_condition_s1[condition] += 1\n",
    "    if len(list(set([\"+er\"]) & set(S_0_utt[example_ind]))) > 0:\n",
    "        comparatives_per_condition_s0[condition] += 1\n",
    "    if len(list(set([\"+er\"]) & set(dev_seqs_test[example_ind]))) > 0:\n",
    "        comparatives_per_condition_human[condition] += 1\n",
    "    if len(list(set([\"+est\"]) & set(S_1_utt[example_ind]))) > 0:\n",
    "        superlatives_per_condition_s1[condition] += 1\n",
    "    if len(list(set([\"+est\"]) & set(S_0_utt[example_ind]))) > 0:\n",
    "        superlatives_per_condition_s0[condition] += 1\n",
    "    if len(list(set([\"+est\"]) & set(dev_seqs_test[example_ind]))) > 0:\n",
    "        superlatives_per_condition_human[condition] += 1\n",
    "    if len(list(set([\"not\"]) & set(S_1_utt[example_ind]))) > 0:\n",
    "        negatives_per_condition_s1[condition] += 1\n",
    "    if len(list(set([\"not\"]) & set(S_0_utt[example_ind]))) > 0:\n",
    "        negatives_per_condition_s0[condition] += 1\n",
    "    if len(list(set([\"not\"]) & set(dev_seqs_test[example_ind]))) > 0:\n",
    "        negatives_per_condition_human[condition] += 1\n",
    "    if len(list(set([\"+ish\"]) & set(S_0_utt[example_ind]))) > 0:\n",
    "        formatives_per_condition_s0[condition] += 1\n",
    "    if len(list(set([\"+ish\"]) & set(S_1_utt[example_ind]))) > 0:\n",
    "        formatives_per_condition_s1[condition] += 1\n",
    "    if len(list(set([\"+ish\"]) & set(dev_seqs_test[example_ind]))) > 0:\n",
    "        formatives_per_condition_human[condition] += 1\n",
    "        \n",
    "    S_0_utt_filtered = filter_seq_without_turns(S_0_utt[example_ind])\n",
    "    S_1_utt_filtered = filter_seq_without_turns(S_1_utt[example_ind])\n",
    "    human_utt_filtered = filter_seq_without_turns(dev_seqs_test[example_ind])\n",
    "        \n",
    "    lengths_per_condition_s0[condition] += len(S_0_utt_filtered)\n",
    "    lengths_per_condition_s1[condition] += len(S_1_utt_filtered)\n",
    "    lengths_per_condition_human[condition] += len(human_utt_filtered)\n",
    "    totals_per_condition[condition] += 1\n",
    "    \n",
    "lengths_per_condition_s0 = {k:v/totals_per_condition[k] for k, v in lengths_per_condition_s0.items()}\n",
    "lengths_per_condition_s1 = {k:v/totals_per_condition[k] for k, v in lengths_per_condition_s1.items()}\n",
    "lengths_per_condition_human = {k:v/totals_per_condition[k] for k, v in lengths_per_condition_human.items()}\n",
    "\n",
    "comparatives_per_condition_s0 = {k:v/totals_per_condition[k]*100 for k, v in comparatives_per_condition_s0.items()}\n",
    "comparatives_per_condition_s1 = {k:v/totals_per_condition[k]*100 for k, v in comparatives_per_condition_s1.items()}\n",
    "comparatives_per_condition_human = {k:v/totals_per_condition[k]*100 for k, v in comparatives_per_condition_human.items()}\n",
    "\n",
    "superlatives_per_condition_s0 = {k:v/totals_per_condition[k]*100 for k, v in superlatives_per_condition_s0.items()}\n",
    "superlatives_per_condition_s1 = {k:v/totals_per_condition[k]*100 for k, v in superlatives_per_condition_s1.items()}\n",
    "superlatives_per_condition_human = {k:v/totals_per_condition[k]*100 for k, v in superlatives_per_condition_human.items()}\n",
    "\n",
    "negatives_per_condition_s0 = {k:v/totals_per_condition[k]*100 for k, v in negatives_per_condition_s0.items()}\n",
    "negatives_per_condition_s1 = {k:v/totals_per_condition[k]*100 for k, v in negatives_per_condition_s1.items()}\n",
    "negatives_per_condition_human = {k:v/totals_per_condition[k]*100 for k, v in negatives_per_condition_human.items()}\n",
    "\n",
    "formatives_per_condition_s0 = {k:v/totals_per_condition[k]*100 for k, v in formatives_per_condition_s0.items()}\n",
    "formatives_per_condition_s1 = {k:v/totals_per_condition[k]*100 for k, v in formatives_per_condition_s1.items()}\n",
    "formatives_per_condition_human = {k:v/totals_per_condition[k]*100 for k, v in formatives_per_condition_human.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"lengths S0\", lengths_per_condition_s0)\n",
    "print(\"lengths S1\", lengths_per_condition_s1)\n",
    "print(\"lengths human\", lengths_per_condition_human)\n",
    "print()\n",
    "print(\"Totals:\",totals_per_condition)\n",
    "print()\n",
    "print(\"comparatives S0\", comparatives_per_condition_s0)\n",
    "print(\"comparatives S1\", comparatives_per_condition_s1)\n",
    "print(\"comparatives human\", comparatives_per_condition_human)\n",
    "print()\n",
    "print(\"superlatives S0\", superlatives_per_condition_s0)\n",
    "print(\"superlatives S1\", superlatives_per_condition_s1)\n",
    "print(\"superlatives human\", superlatives_per_condition_human)\n",
    "print()\n",
    "print(\"negatives S0\", negatives_per_condition_s0)\n",
    "print(\"negatives S1\", negatives_per_condition_s1)\n",
    "print(\"negatives human\", negatives_per_condition_human)\n",
    "print()\n",
    "print(\"formatives S0\", formatives_per_condition_s0)\n",
    "print(\"formatives S1\", formatives_per_condition_s1)\n",
    "print(\"formatives human\", formatives_per_condition_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_0_length_dist = [{k:0 for k in range(20)} for i in range(3)]\n",
    "S_1_length_dist = [{k:0 for k in range(20)} for i in range(3)]\n",
    "human_length_dist = [{k:0 for k in range(20)} for i in range(3)]\n",
    "condition_lookup = {\"far\":0, \"close\":1, \"split\":2}\n",
    "for example_ind in range(len(dev_examples_test)):\n",
    "    condition = dev_examples_test[example_ind].condition\n",
    "    condition = condition_lookup[condition]\n",
    "    S_1_length_dist[condition][len(filter_seq_without_turns(S_1_utt[example_ind]))]+=1\n",
    "    S_0_length_dist[condition][len(filter_seq_without_turns(S_0_utt[example_ind]))]+=1\n",
    "    if len(filter_seq_without_turns(dev_seqs_test[example_ind])) > 19:\n",
    "        human_length_dist[condition][19] += 1\n",
    "    else:\n",
    "        human_length_dist[condition][len(filter_seq_without_turns(dev_seqs_test[example_ind]))]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_length_dist():\n",
    "    import numpy as np\n",
    "    from matplotlib import pyplot\n",
    "\n",
    "    for condition in [\"far\", \"close\", \"split\"]:\n",
    "        print(condition)\n",
    "        condition = condition_lookup[condition]\n",
    "        x = [v for v in S_1_length_dist[condition].values()]\n",
    "        y = [v for v in S_0_length_dist[condition].values()]\n",
    "        z = [v for v in human_length_dist[condition].values()]\n",
    "        print(x,y)\n",
    "\n",
    "        bins = np.arange(20)\n",
    "\n",
    "        pyplot.plot(bins, np.log(np.array(x)+1), label='S1')\n",
    "        pyplot.plot(bins, np.log(np.array(y)+1), label='S0')\n",
    "        pyplot.plot(bins, np.log(np.array(z)+1), label='human')\n",
    "\n",
    "        pyplot.axis((0,18,0,10))\n",
    "        pyplot.legend(loc='upper right')\n",
    "        pyplot.show()\n",
    "plot_length_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener_hallucinating_speaker.listener_accuracy(dev_cols_test, dev_seqs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener_hallucinating_speaker.perplexities(dev_cols_test, dev_seqs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#listener_hallucinating_speaker.save_model(\"listener_hallucinating_speaker.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
